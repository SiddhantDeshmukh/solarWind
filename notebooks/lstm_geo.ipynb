{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import heliopy.data.omni as omni\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "from optuna import visualization as viz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME_CYCLE_21 = datetime(1976, 3, 1)  \n",
    "START_TIME_CYCLE_22 = datetime(1986, 9, 1)  \n",
    "START_TIME_CYCLE_23 = datetime(1996, 8, 1)  \n",
    "START_TIME_CYCLE_24 = datetime(2008, 12, 1)  \n",
    "START_TIME_CYCLE_25 = datetime(2019, 12, 1)\n",
    "\n",
    "INPUT_LENGTH = 100\n",
    "OUTPUT_LENGTH = 24\n",
    "PERCENTILE = 10\n",
    "VARS_TO_PREDICT = [\"N\", \"ABS_B\", \"V\", \"HMF_INC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omni_rtn_data(start_time, end_time):\n",
    "    identifier = 'OMNI_COHO1HR_MERGED_MAG_PLASMA'  # COHO 1HR data\n",
    "    omni_data = omni._omni(start_time, end_time, identifier=identifier, intervals='yearly', warn_missing_units=False)\n",
    "    return omni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hmf(data):\n",
    "    data['HMF_INC'] = np.arctan2(-data['BT'].values, data['BN'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_21 = get_omni_rtn_data(START_TIME_CYCLE_21, START_TIME_CYCLE_22).to_dataframe()\n",
    "cycle_22 = get_omni_rtn_data(START_TIME_CYCLE_22, START_TIME_CYCLE_23).to_dataframe()\n",
    "cycle_23 = get_omni_rtn_data(START_TIME_CYCLE_23, START_TIME_CYCLE_24).to_dataframe()\n",
    "cycle_24 = get_omni_rtn_data(START_TIME_CYCLE_24, START_TIME_CYCLE_25).to_dataframe()\n",
    "\n",
    "calc_hmf(cycle_21)\n",
    "calc_hmf(cycle_22)\n",
    "calc_hmf(cycle_23)\n",
    "calc_hmf(cycle_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_field_strength_21 = np.array(cycle_21[VARS_TO_PREDICT])\n",
    "mag_field_strength_22 = np.array(cycle_22[VARS_TO_PREDICT])\n",
    "mag_field_strength_23 = np.array(cycle_23[VARS_TO_PREDICT])\n",
    "mag_field_strength_24 = np.array(cycle_24[VARS_TO_PREDICT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prepare_nd(multi_array, input_length=INPUT_LENGTH, output_length=OUTPUT_LENGTH):\n",
    "    inputs = np.array([multi_array[i:i + input_length] \n",
    "                           for i in range(len(multi_array) - input_length - output_length + 1)])\n",
    "    outputs = np.array([multi_array[i + input_length:i + input_length + output_length] \n",
    "                            for i in range(len(multi_array) - input_length - output_length + 1)])\n",
    "\n",
    "    nan_check = np.array([multi_array[i:i + input_length + output_length] \n",
    "                              for i in range(len(multi_array) - input_length - output_length + 1)])\n",
    "\n",
    "    inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "    outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Output shape:\", outputs.shape)\n",
    "    print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2524, 100, 4)\n",
      "Output shape: (2524, 24, 4)\n",
      "Any Nans?: False\n",
      "Input shape: (83261, 100, 4)\n",
      "Output shape: (83261, 24, 4)\n",
      "Any Nans?: False\n",
      "Input shape: (10436, 100, 4)\n",
      "Output shape: (10436, 24, 4)\n",
      "Any Nans?: False\n",
      "Input shape: (87202, 100, 4)\n",
      "Output shape: (87202, 24, 4)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "inputs_21, outputs_21 = lstm_prepare_nd(mag_field_strength_21)\n",
    "inputs_23, outputs_23 = lstm_prepare_nd(mag_field_strength_23)\n",
    "inputs_val, outputs_val = lstm_prepare_nd(mag_field_strength_22)\n",
    "inputs_test, outputs_test = lstm_prepare_nd(mag_field_strength_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = np.concatenate([inputs_21, inputs_23])\n",
    "outputs_train = np.concatenate([outputs_21, outputs_23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_field_strength = np.concatenate((mag_field_strength_21, mag_field_strength_23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_norm = (inputs_train - np.nanmean(training_field_strength, axis=0)) / np.nanstd(training_field_strength, axis=0)\n",
    "inputs_val_norm = (inputs_val - np.nanmean(training_field_strength, axis=0)) / np.nanstd(training_field_strength, axis=0)\n",
    "inputs_test_norm = (inputs_test - np.nanmean(training_field_strength, axis=0)) / np.nanstd(training_field_strength, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_initial (LSTM)          (None, None, 32)          4736      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 4)           132       \n",
      "=================================================================\n",
      "Total params: 4,868\n",
      "Trainable params: 4,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2681/2681 - 16s - loss: 42920.1367 - mae: 101.6629 - val_loss: 29044.2402 - val_mae: 83.5657\n",
      "Epoch 2/500\n",
      "2681/2681 - 14s - loss: 27819.7617 - mae: 80.4650 - val_loss: 17413.1328 - val_mae: 63.2139\n",
      "Epoch 3/500\n",
      "2681/2681 - 15s - loss: 16906.2129 - mae: 60.6257 - val_loss: 9427.5967 - val_mae: 43.8149\n",
      "Epoch 4/500\n",
      "2681/2681 - 14s - loss: 9446.4443 - mae: 41.9480 - val_loss: 4660.6938 - val_mae: 26.8412\n",
      "Epoch 5/500\n",
      "2681/2681 - 14s - loss: 5088.0586 - mae: 28.2903 - val_loss: 2673.0623 - val_mae: 20.7352\n",
      "Epoch 6/500\n",
      "2681/2681 - 14s - loss: 3313.8479 - mae: 23.6302 - val_loss: 2545.7776 - val_mae: 22.7200\n",
      "Epoch 7/500\n",
      "2681/2681 - 15s - loss: 2904.8716 - mae: 22.9693 - val_loss: 1496.6523 - val_mae: 15.8366\n",
      "Epoch 8/500\n",
      "2681/2681 - 15s - loss: 1687.5514 - mae: 16.1638 - val_loss: 1077.0825 - val_mae: 13.9952\n",
      "Epoch 9/500\n",
      "2681/2681 - 15s - loss: 1347.5936 - mae: 14.7806 - val_loss: 961.5799 - val_mae: 13.4686\n",
      "Epoch 10/500\n",
      "2681/2681 - 14s - loss: 1237.2777 - mae: 14.2998 - val_loss: 899.8433 - val_mae: 12.8603\n",
      "Epoch 11/500\n",
      "2681/2681 - 14s - loss: 1193.8685 - mae: 14.1054 - val_loss: 934.3865 - val_mae: 13.5366\n",
      "Epoch 12/500\n",
      "2681/2681 - 14s - loss: 1172.3489 - mae: 14.0048 - val_loss: 908.6991 - val_mae: 13.2233\n",
      "Epoch 13/500\n",
      "2681/2681 - 14s - loss: 1159.9418 - mae: 13.9381 - val_loss: 912.8682 - val_mae: 13.3128\n",
      "Epoch 14/500\n",
      "2681/2681 - 14s - loss: 1151.2714 - mae: 13.8953 - val_loss: 915.3925 - val_mae: 13.3772\n",
      "Epoch 15/500\n",
      "2681/2681 - 14s - loss: 1143.5284 - mae: 13.8499 - val_loss: 921.5052 - val_mae: 13.4223\n",
      "Epoch 16/500\n",
      "2681/2681 - 14s - loss: 1138.2821 - mae: 13.8164 - val_loss: 877.5480 - val_mae: 12.8919\n",
      "Epoch 17/500\n",
      "2681/2681 - 14s - loss: 1132.9553 - mae: 13.7734 - val_loss: 925.7295 - val_mae: 13.5529\n",
      "Epoch 18/500\n",
      "2681/2681 - 15s - loss: 1128.3053 - mae: 13.7379 - val_loss: 911.0348 - val_mae: 13.4357\n",
      "Epoch 19/500\n",
      "2681/2681 - 14s - loss: 1125.1440 - mae: 13.7134 - val_loss: 885.1653 - val_mae: 13.0269\n",
      "Epoch 20/500\n",
      "2681/2681 - 17s - loss: 1121.6062 - mae: 13.6935 - val_loss: 878.1409 - val_mae: 12.9892\n",
      "Epoch 21/500\n",
      "2681/2681 - 16s - loss: 1119.2444 - mae: 13.6782 - val_loss: 920.4905 - val_mae: 13.4144\n",
      "Epoch 22/500\n",
      "2681/2681 - 15s - loss: 1116.2607 - mae: 13.6576 - val_loss: 891.3550 - val_mae: 13.0850\n",
      "Epoch 23/500\n",
      "2681/2681 - 16s - loss: 1113.1429 - mae: 13.6313 - val_loss: 882.9147 - val_mae: 13.0120\n",
      "Epoch 24/500\n",
      "2681/2681 - 14s - loss: 1110.6741 - mae: 13.6146 - val_loss: 904.0091 - val_mae: 13.2163\n",
      "Epoch 25/500\n",
      "2681/2681 - 15s - loss: 1108.6815 - mae: 13.6017 - val_loss: 897.8926 - val_mae: 13.1561\n",
      "Epoch 26/500\n",
      "2681/2681 - 15s - loss: 1106.7452 - mae: 13.5873 - val_loss: 878.8786 - val_mae: 12.8937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa691a5f4a8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(32, name=\"lstm_initial\", input_shape=(None, 4), return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(4, name=\"dense_final\", activation=\"linear\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train_norm[:, -24:], outputs_train, validation_data=(inputs_val_norm[:, -24:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2726/2726 - 4s - loss: 862.2397 - mae: 12.2619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[862.2396850585938, 12.261914253234863]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_test_norm[:, -24:], outputs_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enc-Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2681/2681 - 32s - loss: 43256.1328 - mae: 102.0516 - val_loss: 29504.4727 - val_mae: 84.2721\n",
      "Epoch 2/500\n",
      "2681/2681 - 32s - loss: 28397.6562 - mae: 81.3791 - val_loss: 17916.0234 - val_mae: 64.2242\n",
      "Epoch 3/500\n",
      "2681/2681 - 31s - loss: 17403.4199 - mae: 61.6775 - val_loss: 9786.0732 - val_mae: 44.8820\n",
      "Epoch 4/500\n",
      "2681/2681 - 30s - loss: 9779.6396 - mae: 42.9435 - val_loss: 4847.8008 - val_mae: 27.5768\n",
      "Epoch 5/500\n",
      "2681/2681 - 30s - loss: 5263.9385 - mae: 28.8244 - val_loss: 2725.8521 - val_mae: 20.7626\n",
      "Epoch 6/500\n",
      "2681/2681 - 30s - loss: 3364.1909 - mae: 23.7033 - val_loss: 2531.9863 - val_mae: 22.5718\n",
      "Epoch 7/500\n",
      "2681/2681 - 31s - loss: 3013.7195 - mae: 23.6316 - val_loss: 2687.5671 - val_mae: 23.8510\n",
      "Epoch 8/500\n",
      "2681/2681 - 30s - loss: 3004.7771 - mae: 23.7871 - val_loss: 2697.4863 - val_mae: 23.9205\n",
      "Epoch 9/500\n",
      "2681/2681 - 28s - loss: 3004.6501 - mae: 23.7911 - val_loss: 2696.4646 - val_mae: 23.9086\n",
      "Epoch 10/500\n",
      "2681/2681 - 30s - loss: 3004.5981 - mae: 23.7927 - val_loss: 2695.0420 - val_mae: 23.9081\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-1036c829ebc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m model.fit(inputs_train_norm[:, -24:], outputs_train, validation_data=(inputs_val_norm[:, -24:], outputs_val),\n\u001b[1;32m     13\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(32, name=\"lstm_initial\", input_shape=(None, 4)),\n",
    "        keras.layers.RepeatVector(24),\n",
    "        keras.layers.LSTM(32, name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(4, name=\"dense_final\", activation=\"linear\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train_norm[:, -24:], outputs_train, validation_data=(inputs_val_norm[:, -24:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/62948332/how-to-add-attention-layer-to-a-bi-lstm/62949137#62949137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "class CustomAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(CustomAttention, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                               initializer=\"zeros\")\n",
    "        super(CustomAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2681/2681 - 35s - loss: 43010.5430 - mae: 101.7500 - val_loss: 29149.6367 - val_mae: 83.7246\n",
      "Epoch 2/500\n",
      "2681/2681 - 31s - loss: 28042.7207 - mae: 80.8158 - val_loss: 17638.2891 - val_mae: 63.6769\n",
      "Epoch 3/500\n",
      "2681/2681 - 34s - loss: 17134.1328 - mae: 61.1237 - val_loss: 9595.6865 - val_mae: 44.3188\n",
      "Epoch 4/500\n",
      "2681/2681 - 32s - loss: 9600.2656 - mae: 42.4284 - val_loss: 4746.8755 - val_mae: 27.1750\n",
      "Epoch 5/500\n",
      "2681/2681 - 34s - loss: 5169.5757 - mae: 28.5507 - val_loss: 2696.8542 - val_mae: 20.7153\n",
      "Epoch 6/500\n",
      "2681/2681 - 33s - loss: 3334.8081 - mae: 23.6412 - val_loss: 2540.6685 - val_mae: 22.6493\n",
      "Epoch 7/500\n",
      "2681/2681 - 31s - loss: 2305.2158 - mae: 19.0693 - val_loss: 1009.8711 - val_mae: 12.4129\n",
      "Epoch 8/500\n",
      "2681/2681 - 33s - loss: 1228.6946 - mae: 13.5021 - val_loss: 722.8624 - val_mae: 11.3882\n",
      "Epoch 9/500\n",
      "2681/2681 - 30s - loss: 936.4607 - mae: 12.0814 - val_loss: 615.4857 - val_mae: 10.6101\n",
      "Epoch 10/500\n",
      "2681/2681 - 32s - loss: 802.1810 - mae: 11.2938 - val_loss: 561.2046 - val_mae: 10.3087\n",
      "Epoch 11/500\n",
      "2681/2681 - 32s - loss: 735.6933 - mae: 10.8613 - val_loss: 611.7059 - val_mae: 11.2595\n",
      "Epoch 12/500\n",
      "2681/2681 - 32s - loss: 703.8041 - mae: 10.6539 - val_loss: 534.3751 - val_mae: 10.0875\n",
      "Epoch 13/500\n",
      "2681/2681 - 30s - loss: 683.3094 - mae: 10.5056 - val_loss: 485.4785 - val_mae: 9.3864\n",
      "Epoch 14/500\n",
      "2681/2681 - 31s - loss: 668.6151 - mae: 10.3954 - val_loss: 499.2260 - val_mae: 9.5275\n",
      "Epoch 15/500\n",
      "2681/2681 - 31s - loss: 658.6260 - mae: 10.3292 - val_loss: 549.1879 - val_mae: 10.2749\n",
      "Epoch 16/500\n",
      "2681/2681 - 32s - loss: 648.7337 - mae: 10.2472 - val_loss: 490.9099 - val_mae: 9.4760\n",
      "Epoch 17/500\n",
      "2681/2681 - 31s - loss: 639.7437 - mae: 10.1853 - val_loss: 527.1989 - val_mae: 10.0713\n",
      "Epoch 18/500\n",
      "2681/2681 - 32s - loss: 632.6725 - mae: 10.1196 - val_loss: 498.1840 - val_mae: 9.6999\n",
      "Epoch 19/500\n",
      "2681/2681 - 31s - loss: 627.8782 - mae: 10.0913 - val_loss: 491.3348 - val_mae: 9.5576\n",
      "Epoch 20/500\n",
      "2681/2681 - 32s - loss: 621.1324 - mae: 10.0336 - val_loss: 538.6411 - val_mae: 9.9959\n",
      "Epoch 21/500\n",
      "2681/2681 - 34s - loss: 617.1151 - mae: 9.9984 - val_loss: 490.0388 - val_mae: 9.6162\n",
      "Epoch 22/500\n",
      "2681/2681 - 31s - loss: 612.0799 - mae: 9.9640 - val_loss: 500.8072 - val_mae: 9.7063\n",
      "Epoch 23/500\n",
      "2681/2681 - 31s - loss: 606.3530 - mae: 9.9180 - val_loss: 514.5254 - val_mae: 9.8602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa69d8ad438>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(32, name=\"lstm_initial\", input_shape=(24, 4), return_sequences=True),\n",
    "        CustomAttention(return_sequences=True),\n",
    "        keras.layers.LSTM(32, name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(4, name=\"dense_final\", activation=\"linear\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train_norm[:, -24:], outputs_train, validation_data=(inputs_val_norm[:, -24:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2726/2726 - 7s - loss: 500.0357 - mae: 9.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[500.0356750488281, 9.290789604187012]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_test_norm[:, -24:], outputs_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2681/2681 - 7s - loss: 668.3700 - mae: 10.2056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[668.3699951171875, 10.20560359954834]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_train_norm[:, -24:], outputs_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 - 1s - loss: 485.4785 - mae: 9.3864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[485.47845458984375, 9.38636589050293]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_val_norm[:, -24:], outputs_val, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2681/2681 - 91s - loss: 24372.3184 - mae: 72.0005 - val_loss: 6000.4502 - val_mae: 32.0991\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-5591da5822ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m model.fit(inputs_train_norm[:, -24:], outputs_train, validation_data=(inputs_val_norm[:, -24:], outputs_val),\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_pulseox_quality/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(64, name=\"lstm_initial\", input_shape=(24, 4), return_sequences=True),\n",
    "        keras.layers.LSTM(128, return_sequences=True),\n",
    "        CustomAttention(return_sequences=True),\n",
    "        keras.layers.LSTM(128, name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(4, name=\"dense_final\", activation=\"linear\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train_norm[:, -24:], outputs_train, validation_data=(inputs_val_norm[:, -24:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention with larger input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_initial (LSTM)          (None, 100, 32)           4736      \n",
      "_________________________________________________________________\n",
      "custom_attention_43 (CustomA (None, 100, 32)           132       \n",
      "_________________________________________________________________\n",
      "lstm_second (LSTM)           (None, 100, 32)           8320      \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 100, 4)            132       \n",
      "_________________________________________________________________\n",
      "cropping1d_12 (Cropping1D)   (None, 24, 4)             0         \n",
      "=================================================================\n",
      "Total params: 13,320\n",
      "Trainable params: 13,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(32, name=\"lstm_initial\", input_shape=(100, 4), return_sequences=True),\n",
    "        CustomAttention(return_sequences=True),\n",
    "        keras.layers.LSTM(32, name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(4, name=\"dense_final\", activation=\"linear\")),\n",
    "        keras.layers.Cropping1D(cropping=(0, 76))\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train_norm[:, -100:], outputs_train, validation_data=(inputs_val_norm[:, -100:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1627.9448\n",
      "16.589468\n",
      "\n",
      "1189.4584\n",
      "14.248516\n",
      "\n",
      "1226.7482\n",
      "14.479452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last 24\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = inp[:, -24:, :]\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797.5559\n",
      "10.708757\n",
      "\n",
      "584.09076\n",
      "9.458246\n",
      "\n",
      "596.2808\n",
      "9.441223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last 1, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(inp[:, -1:, :], 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372.0238\n",
      "14.951957\n",
      "\n",
      "1006.5172\n",
      "12.818467\n",
      "\n",
      "1035.1685\n",
      "13.03555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean of last 24, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(np.reshape(np.mean(inp[:, -24:, :], axis=1), (len(inp), 1, 4)), 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501.9717\n",
      "21.087082\n",
      "\n",
      "2002.0676\n",
      "18.584085\n",
      "\n",
      "1891.9309\n",
      "18.228844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean of last 100, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(np.reshape(np.mean(inp[:, -100:, :], axis=1), (len(inp), 1, 4)), 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1466.1205\n",
      "15.213919\n",
      "\n",
      "1083.7523\n",
      "13.031278\n",
      "\n",
      "1107.4498\n",
      "13.255629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Median of last 24, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(np.reshape(np.median(inp[:, -24:, :], axis=1), (len(inp), 1, 4)), 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003.5787\n",
      "20.203812\n",
      "\n",
      "1361.8109\n",
      "17.362165\n",
      "\n",
      "1430.5306\n",
      "17.416336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max of last 24, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(np.reshape(np.max(inp[:, -24:, :], axis=1), (len(inp), 1, 4)), 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1933.7264\n",
      "16.220797\n",
      "\n",
      "1456.5176\n",
      "14.380861\n",
      "\n",
      "1506.6075\n",
      "14.450279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min of last 24, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(np.reshape(np.min(inp[:, -24:, :], axis=1), (len(inp), 1, 4)), 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443.1892\n",
      "20.533897\n",
      "\n",
      "1775.3417\n",
      "17.520683\n",
      "\n",
      "1833.1857\n",
      "17.77644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 24 ago, repeated\n",
    "for inp, out in zip([inputs_train, inputs_val, inputs_test], [outputs_train, outputs_val, outputs_test]):\n",
    "    outputs_pred = np.repeat(inp[:, -24:-23, :], 24, axis=1)\n",
    "    print(np.mean((out - outputs_pred) ** 2))\n",
    "    print(np.mean(np.abs((out - outputs_pred))))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
