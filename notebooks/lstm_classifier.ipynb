{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import heliopy.data.omni as omni\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "from optuna import visualization as viz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME_CYCLE_21 = datetime(1976, 3, 1)  \n",
    "START_TIME_CYCLE_22 = datetime(1986, 9, 1)  \n",
    "START_TIME_CYCLE_23 = datetime(1996, 8, 1)  \n",
    "START_TIME_CYCLE_24 = datetime(2008, 12, 1)  \n",
    "START_TIME_CYCLE_25 = datetime(2019, 12, 1)\n",
    "\n",
    "INPUT_LENGTH = 100\n",
    "OUTPUT_LENGTH = 24\n",
    "PERCENTILE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omni_rtn_data(start_time, end_time):\n",
    "    identifier = 'OMNI_COHO1HR_MERGED_MAG_PLASMA'  # COHO 1HR data\n",
    "    omni_data = omni._omni(start_time, end_time, identifier=identifier, intervals='yearly', warn_missing_units=False)\n",
    "    return omni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_21 = get_omni_rtn_data(START_TIME_CYCLE_21, START_TIME_CYCLE_22).to_dataframe()\n",
    "cycle_22 = get_omni_rtn_data(START_TIME_CYCLE_22, START_TIME_CYCLE_23).to_dataframe()\n",
    "cycle_23 = get_omni_rtn_data(START_TIME_CYCLE_23, START_TIME_CYCLE_24).to_dataframe()\n",
    "cycle_24 = get_omni_rtn_data(START_TIME_CYCLE_24, START_TIME_CYCLE_25).to_dataframe()\n",
    "\n",
    "mag_field_strength_21 = np.array(cycle_21[\"BR\"])\n",
    "mag_field_strength_22 = np.array(cycle_22[\"BR\"])\n",
    "mag_field_strength_23 = np.array(cycle_23[\"BR\"])\n",
    "mag_field_strength_24 = np.array(cycle_24[\"BR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prepare_1d(mag_field_strength, input_length=INPUT_LENGTH, output_length=OUTPUT_LENGTH):\n",
    "    inputs = np.array([mag_field_strength[i:i + input_length] \n",
    "                       for i in range(len(mag_field_strength) - input_length)])[:, :, np.newaxis]\n",
    "    outputs = np.array([mag_field_strength[i + input_length:i + input_length + output_length] \n",
    "                        for i in range(len(mag_field_strength) - input_length - output_length)])\n",
    "\n",
    "\n",
    "    nan_check = np.array([mag_field_strength[i:i + input_length + output_length] \n",
    "                          for i in range(len(mag_field_strength) - input_length - output_length)])\n",
    "\n",
    "    inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "    outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "    \n",
    "\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Output shape:\", outputs.shape)\n",
    "    print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))\n",
    "    print(\"\")\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (5132, 100, 1)\n",
      "Output shape: (5132, 24)\n",
      "Any Nans?: False\n",
      "\n",
      "Input shape: (105288, 100, 1)\n",
      "Output shape: (105288, 24)\n",
      "Any Nans?: False\n",
      "\n",
      "Input shape: (11376, 100, 1)\n",
      "Output shape: (11376, 24)\n",
      "Any Nans?: False\n",
      "\n",
      "Input shape: (95144, 100, 1)\n",
      "Output shape: (95144, 24)\n",
      "Any Nans?: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs_21, outputs_21 = lstm_prepare_1d(mag_field_strength_21)\n",
    "inputs_23, outputs_23 = lstm_prepare_1d(mag_field_strength_23)\n",
    "inputs_val, outputs_val = lstm_prepare_1d(mag_field_strength_22)\n",
    "inputs_test, outputs_test = lstm_prepare_1d(mag_field_strength_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = np.concatenate([inputs_21, inputs_23])\n",
    "outputs_train = np.concatenate([outputs_21, outputs_23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_field_strength = np.concatenate([mag_field_strength_21, mag_field_strength_23])\n",
    "training_field_strength = training_field_strength[training_field_strength == training_field_strength]\n",
    "solar_storm = np.percentile(training_field_strength, PERCENTILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_train = np.any(outputs_train <= solar_storm, axis=1).astype(int)\n",
    "outputs_val = np.any(outputs_val <= solar_storm, axis=1).astype(int)\n",
    "outputs_test = np.any(outputs_test <= solar_storm, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_norm = (inputs_train - np.nanmean(training_field_strength)) / np.nanstd(training_field_strength)\n",
    "inputs_val_norm = (inputs_val - np.nanmean(training_field_strength)) / np.nanstd(training_field_strength)\n",
    "inputs_test_norm = (inputs_test - np.nanmean(training_field_strength)) / np.nanstd(training_field_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline val acc: 0.6044303797468354\n",
      "Baseline train acc: 0.6679224778119905\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline val acc:\", 1 - outputs_val.sum() / len(outputs_val))\n",
    "print(\"Baseline train acc:\", 1 - outputs_train.sum() / len(outputs_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(outputs_train),\n",
    "                                                 outputs_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]\n",
    "\n",
    "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_data, y_data = self.data\n",
    "        x_result = self.model.predict(x_data, verbose=0)\n",
    "\n",
    "        correct, incorrect = 0, 0\n",
    "        class_correct, class_incorrect = np.zeros(len(classes)), np.zeros(len(classes))\n",
    "        for i in range(len(x_data)):\n",
    "            pred_label = np.round(x_result[i])\n",
    "            actual_label = y_data[i]\n",
    "            if pred_label == actual_label:\n",
    "                class_correct[actual_label] += 1   \n",
    "                correct += 1\n",
    "            else:\n",
    "                class_incorrect[actual_label] += 1\n",
    "                incorrect += 1\n",
    "\n",
    "        print(\"\\tCorrect: %d\" %(correct))\n",
    "        print(\"\\tIncorrect: %d\" %(incorrect))\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            tot = float(class_correct[i] + class_incorrect[i])\n",
    "            class_acc = -1\n",
    "            if (tot > 0):\n",
    "                class_acc = float(class_correct[i]) / tot\n",
    "\n",
    "            print(\"\\t%s: %.3f\" %(classes[i], class_acc)) \n",
    "\n",
    "        acc = float(correct) / float(correct + incorrect)  \n",
    "        print(\"\\tCurrent Network Accuracy: %.3f\" %(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(32, name=\"lstm_initial\", input_shape=(None, 1)),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(inputs_train_norm, outputs_train, validation_data=(inputs_val_norm, outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     AccuracyCallback((inputs_val_norm, outputs_val))],\n",
    "          class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(16, input_shape=(None, 1), return_sequences=True),\n",
    "        keras.layers.LSTM(32),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(inputs_train_norm[:, -i:], outputs_train, validation_data=(inputs_val_norm[:, -i:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     AccuracyCallback((inputs_val_norm[:, -i:], outputs_val))],\n",
    "          class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(16, input_shape=(None, 1), return_sequences=True, recurrent_dropout=0.2),\n",
    "        keras.layers.LSTM(32, recurrent_dropout=0.2),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(inputs_train_norm[:, -i:], outputs_train, validation_data=(inputs_val_norm[:, -i:], outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     AccuracyCallback((inputs_val_norm[:, -i:], outputs_val))],\n",
    "          class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What baselines are we doing? AnEn, SVM, mean/median/last/first, all zeros\n",
    "# 2. Which percentile do we pick? \n",
    "# 3. Sounds like we only care about a large negative value right? A: Yes\n",
    "# 4. So it sounds like it's not relative value, or did he misinterpret the question? A: Probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max task\n",
    "# 1. Get test subset for AnEn\n",
    "# 2. Change output to not do absolute value \n",
    "# 3. RUn some initial baselines\n",
    "\n",
    "# Their data range: 01 Jan 1995 to end of Dec 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
