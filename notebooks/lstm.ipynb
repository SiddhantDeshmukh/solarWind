{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import heliopy.data.omni as omni\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "from optuna import visualization as viz\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = datetime(1995, 1, 1)\n",
    "END_TIME = datetime(2018, 2, 28)\n",
    "INPUT_LENGTH = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omni_rtn_data(start_time, end_time):\n",
    "    identifier = 'OMNI_COHO1HR_MERGED_MAG_PLASMA'  # COHO 1HR data\n",
    "    omni_data = omni._omni(start_time, end_time, identifier=identifier, intervals='yearly', warn_missing_units=False)\n",
    "    return omni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_omni_rtn_data(START_TIME, END_TIME).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_field_strength = np.array(data[\"BR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split into INPUT_LENGTH sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (201389, 24, 1)\n",
      "Output shape: (201389,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis]\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:])\n",
    "\n",
    "nan_check = np.array([mag_field_strength[i:i + INPUT_LENGTH + 1] \n",
    "                      for i in range(len(mag_field_strength) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this time-based, so most recent = test set, earliest = train set \n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1: Last timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dset, out in zip([\"last_train\", \"last_val\", \"last_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, -1, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2: Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dset, out in zip([\"mean_train\", \"mean_val\", \"mean_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.mean(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3: Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dset, out in zip([\"median_train\", \"median_val\", \"median_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.median(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4: Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dset, out in zip([\"start_train\", \"start_val\", \"start_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, 0, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initial LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 1), return_sequences=True),\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_second\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/baseline_model.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Repeat above but use more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise all variables \n",
    "data_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (189110, 24, 11)\n",
      "Output shape: (189110,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "# Split into INPUT_LENGTH sections\n",
    "inputs = np.array([data_array[i:i + INPUT_LENGTH] for i in range(len(data_array) - INPUT_LENGTH)])\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:]) # np.array(data_array[INPUT_LENGTH:, 2])\n",
    "\n",
    "nan_check = np.array([data_array[i:i + INPUT_LENGTH + 1] for i in range(len(data_array) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 132377\n",
      "Val size: 28366\n",
      "Test size: 28367\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "\n",
    "# standardize\n",
    "inputs_val = (inputs_val - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "inputs_test = (inputs_test - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "inputs_train = (inputs_train - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(16, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 11), return_sequences=True),\n",
    "        keras.layers.LSTM(32, activation=\"relu\", name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.LSTM(64, activation=\"relu\", name=\"lstm_third\"),\n",
    "        keras.layers.Dense(128, name=\"dense_initial\", activation=\"relu\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/baseline_model_multivar.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_layers: int, num_in_lstm_layers: List[int], \n",
    "                 dense_layers: int, num_in_dense_layers: List[int]) -> keras.models.Model:\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(lstm_layers):\n",
    "        if i == 0:\n",
    "            if i + 1 != lstm_layers:\n",
    "                model.add(keras.layers.LSTM(num_in_lstm_layers[i], input_shape=(None, 11), return_sequences=True))\n",
    "            else:\n",
    "                model.add(keras.layers.LSTM(num_in_lstm_layers[i], input_shape=(None, 11)))\n",
    "        elif i != 0 and i + 1 == lstm_layers:\n",
    "            model.add(keras.layers.LSTM(num_in_lstm_layers[i]))\n",
    "        else:\n",
    "            model.add(keras.layers.LSTM(num_in_lstm_layers[i], input_shape=(None, 11), return_sequences=True))\n",
    "            \n",
    "    for i in range(dense_layers):\n",
    "        if i + 1 == dense_layers:\n",
    "            model.add(keras.layers.Dense(num_in_dense_layers[i], activation=\"linear\"))\n",
    "        else:\n",
    "            model.add(keras.layers.Dense(num_in_dense_layers[i], activation=\"relu\"))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 7)\n",
    "    layer_choices = [[4, 8, 16, 32, 64, 128, 256], [8, 16, 32, 64, 128, 256, 512],\n",
    "                     [16, 32, 64, 128, 256, 512, 1024]]\n",
    "    lstm_layer_choice = trial.suggest_categorical(\"lstm_layer_choice\", layer_choices)\n",
    "    lstm_layer_choice = lstm_layer_choice[:lstm_layers]\n",
    "    \n",
    "    dense_layers = trial.suggest_int(\"dense_layers\", 1, 4)\n",
    "    layer_choices = [[1024, 512, 256, 1], [512, 256, 128, 1], [128, 64, 32, 1]]\n",
    "    dense_layer_choice = trial.suggest_categorical(\"dense_layer_choice\", layer_choices)\n",
    "    dense_layer_choice = dense_layer_choice[4 - dense_layers:]\n",
    "    \n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 2e-1, 1e-2])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    \n",
    "    model = create_model(lstm_layers, lstm_layer_choice, dense_layers, dense_layer_choice)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "              batch_size=batch_size, epochs=500, \n",
    "              callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)],\n",
    "              verbose=2)\n",
    "\n",
    "    return model.evaluate(inputs_val, outputs_val)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective, n_trials=100)  # Invoke optimization of the objective function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
