{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import heliopy.data.omni as omni\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = datetime(1995, 1, 1)\n",
    "END_TIME = datetime(2018, 2, 28)\n",
    "INPUT_LENGTH = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omni_rtn_data(start_time, end_time):\n",
    "    identifier = 'OMNI_COHO1HR_MERGED_MAG_PLASMA'  # COHO 1HR data\n",
    "    omni_data = omni._omni(start_time, end_time, identifier=identifier, intervals='yearly', warn_missing_units=False)\n",
    "    return omni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_omni_rtn_data(START_TIME, END_TIME).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_field_strength = np.array(data[\"BR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split into INPUT_LENGTH sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (201389, 24, 1)\n",
      "Output shape: (201389,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis]\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:])\n",
    "\n",
    "nan_check = np.array([mag_field_strength[i:i + INPUT_LENGTH + 1] \n",
    "                      for i in range(len(mag_field_strength) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140972\n",
      "Val size: 30208\n",
      "Test size: 30209\n"
     ]
    }
   ],
   "source": [
    "# Doing this time-based, so most recent = test set, earliest = train set \n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1: Last timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE last_train: 3.14658\n",
      "MSE last_val: 2.4640298\n",
      "MSE last_test: 3.3855927\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"last_train\", \"last_val\", \"last_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, -1, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2: Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE mean_train: 6.9930334\n",
      "MSE mean_val: 5.7877436\n",
      "MSE mean_test: 6.955669\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"mean_train\", \"mean_val\", \"mean_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.mean(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3: Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE median_train: 7.735584\n",
      "MSE median_val: 6.426136\n",
      "MSE median_test: 7.6656737\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"median_train\", \"median_val\", \"median_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.median(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4: Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE start_train: 15.318962\n",
      "MSE start_val: 12.723228\n",
      "MSE start_test: 15.642863\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"start_train\", \"start_val\", \"start_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, 0, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initial LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 1), return_sequences=True),\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_second\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=30, \n",
    "          callbacks=keras.callbacks.EarlyStopping(restore_best_weights=True, patience=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Repeat above but use more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise all variables \n",
    "data_array = np.array(data)\n",
    "data_array = (data_array - np.nanmean(data_array, axis=0)) / np.nanstd(data_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (189110, 24, 11)\n",
      "Output shape: (189110,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "# Split into INPUT_LENGTH sections\n",
    "inputs = np.array([data_array[i:i + INPUT_LENGTH] for i in range(len(data_array) - INPUT_LENGTH)])\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:]) # np.array(data_array[INPUT_LENGTH:, 2])\n",
    "\n",
    "nan_check = np.array([data_array[i:i + INPUT_LENGTH + 1] for i in range(len(data_array) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 132377\n",
      "Val size: 28366\n",
      "Test size: 28367\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(50, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 11), return_sequences=True),\n",
    "        keras.layers.LSTM(50, activation=\"relu\", name=\"lstm_second\"),\n",
    "        keras.layers.Dense(10, name=\"dense_initial\", activation=\"relu\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=30, \n",
    "          callbacks=keras.callbacks.EarlyStopping(restore_best_weights=True, patience=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=30, \n",
    "          callbacks=keras.callbacks.EarlyStopping(restore_best_weights=True, patience=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=keras.callbacks.EarlyStopping(restore_best_weights=True, patience=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(inputs_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
