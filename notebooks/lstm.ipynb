{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import heliopy.data.omni as omni\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = datetime(1995, 1, 1)\n",
    "END_TIME = datetime(2018, 2, 28)\n",
    "INPUT_LENGTH = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omni_rtn_data(start_time, end_time):\n",
    "    identifier = 'OMNI_COHO1HR_MERGED_MAG_PLASMA'  # COHO 1HR data\n",
    "    omni_data = omni._omni(start_time, end_time, identifier=identifier, intervals='yearly', warn_missing_units=False)\n",
    "    return omni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_omni_rtn_data(START_TIME, END_TIME).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_field_strength = np.array(data[\"BR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split into INPUT_LENGTH sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203014"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (201389, 24, 1)\n",
      "Output shape: (201389,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis]\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:])\n",
    "\n",
    "nan_check = np.array([mag_field_strength[i:i + INPUT_LENGTH + 1] \n",
    "                      for i in range(len(mag_field_strength) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140972\n",
      "Val size: 30208\n",
      "Test size: 30209\n"
     ]
    }
   ],
   "source": [
    "# Doing this time-based, so most recent = test set, earliest = train set \n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1: Last timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE last_train: 3.14658\n",
      "MSE last_val: 2.4640298\n",
      "MSE last_test: 3.3855927\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"last_train\", \"last_val\", \"last_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, -1, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2: Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE mean_train: 6.9930334\n",
      "MSE mean_val: 5.7877436\n",
      "MSE mean_test: 6.955669\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"mean_train\", \"mean_val\", \"mean_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.mean(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3: Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE median_train: 7.735584\n",
      "MSE median_val: 6.426136\n",
      "MSE median_test: 7.6656737\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"median_train\", \"median_val\", \"median_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.median(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4: Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE start_train: 15.318962\n",
      "MSE start_val: 12.723228\n",
      "MSE start_test: 15.642863\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"start_train\", \"start_val\", \"start_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, 0, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initial LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_initial (LSTM)          (None, None, 20)          1760      \n",
      "_________________________________________________________________\n",
      "lstm_second (LSTM)           (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 5,061\n",
      "Trainable params: 5,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 1), return_sequences=True),\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_second\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4406/4406 [==============================] - 49s 11ms/step - loss: 3.9519 - mae: 1.3903 - val_loss: 2.4507 - val_mae: 1.0843\n",
      "Epoch 2/500\n",
      "4406/4406 [==============================] - 50s 11ms/step - loss: 2.9383 - mae: 1.1882 - val_loss: 2.3057 - val_mae: 1.0419\n",
      "Epoch 3/500\n",
      "4406/4406 [==============================] - 50s 11ms/step - loss: 2.8879 - mae: 1.1787 - val_loss: 2.2745 - val_mae: 1.0251\n",
      "Epoch 4/500\n",
      "4406/4406 [==============================] - 49s 11ms/step - loss: 2.8645 - mae: 1.1744 - val_loss: 2.2521 - val_mae: 1.0317\n",
      "Epoch 5/500\n",
      "4406/4406 [==============================] - 50s 11ms/step - loss: 2.8586 - mae: 1.1732 - val_loss: 2.2491 - val_mae: 1.0301\n",
      "Epoch 6/500\n",
      "4406/4406 [==============================] - 44s 10ms/step - loss: 2.8483 - mae: 1.1719 - val_loss: 2.2724 - val_mae: 1.0417\n",
      "Epoch 7/500\n",
      "4406/4406 [==============================] - 44s 10ms/step - loss: 2.8402 - mae: 1.1697 - val_loss: 2.2659 - val_mae: 1.0476\n",
      "Epoch 8/500\n",
      "4406/4406 [==============================] - 47s 11ms/step - loss: 2.8352 - mae: 1.1695 - val_loss: 2.2480 - val_mae: 1.0299\n",
      "Epoch 9/500\n",
      "4406/4406 [==============================] - 51s 12ms/step - loss: 2.8290 - mae: 1.1680 - val_loss: 2.2589 - val_mae: 1.0297\n",
      "Epoch 10/500\n",
      "4406/4406 [==============================] - 51s 12ms/step - loss: 2.8289 - mae: 1.1690 - val_loss: 2.2433 - val_mae: 1.0294\n",
      "Epoch 11/500\n",
      "4406/4406 [==============================] - 46s 11ms/step - loss: 2.8235 - mae: 1.1682 - val_loss: 2.2388 - val_mae: 1.0321\n",
      "Epoch 12/500\n",
      "4406/4406 [==============================] - 48s 11ms/step - loss: 2.8224 - mae: 1.1680 - val_loss: 2.2848 - val_mae: 1.0502\n",
      "Epoch 13/500\n",
      "4406/4406 [==============================] - 48s 11ms/step - loss: 2.8196 - mae: 1.1677 - val_loss: 2.2620 - val_mae: 1.0362\n",
      "Epoch 14/500\n",
      "4406/4406 [==============================] - 48s 11ms/step - loss: 2.8164 - mae: 1.1673 - val_loss: 2.2611 - val_mae: 1.0275\n",
      "Epoch 15/500\n",
      "4406/4406 [==============================] - 47s 11ms/step - loss: 2.8134 - mae: 1.1664 - val_loss: 2.2432 - val_mae: 1.0289\n",
      "Epoch 16/500\n",
      "4406/4406 [==============================] - 54s 12ms/step - loss: 2.8100 - mae: 1.1656 - val_loss: 2.2472 - val_mae: 1.0253\n",
      "Epoch 17/500\n",
      "4406/4406 [==============================] - 47s 11ms/step - loss: 2.8102 - mae: 1.1657 - val_loss: 2.2515 - val_mae: 1.0329\n",
      "Epoch 18/500\n",
      "4406/4406 [==============================] - 49s 11ms/step - loss: 2.8079 - mae: 1.1652 - val_loss: 2.2551 - val_mae: 1.0413\n",
      "Epoch 19/500\n",
      "4406/4406 [==============================] - 49s 11ms/step - loss: 2.8046 - mae: 1.1649 - val_loss: 2.2432 - val_mae: 1.0236\n",
      "Epoch 20/500\n",
      "4406/4406 [==============================] - 51s 12ms/step - loss: 2.8045 - mae: 1.1655 - val_loss: 2.2519 - val_mae: 1.0259\n",
      "Epoch 21/500\n",
      "4406/4406 [==============================] - 54s 12ms/step - loss: 2.8012 - mae: 1.1647 - val_loss: 2.2439 - val_mae: 1.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6434b5390>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/baseline_model.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 3.0155 - mae: 1.2339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0155394077301025, 1.2338838577270508]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Repeat above but use more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise all variables \n",
    "data_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (189110, 24, 11)\n",
      "Output shape: (189110,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "# Split into INPUT_LENGTH sections\n",
    "inputs = np.array([data_array[i:i + INPUT_LENGTH] for i in range(len(data_array) - INPUT_LENGTH)])\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:]) # np.array(data_array[INPUT_LENGTH:, 2])\n",
    "\n",
    "nan_check = np.array([data_array[i:i + INPUT_LENGTH + 1] for i in range(len(data_array) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 132377\n",
      "Val size: 28366\n",
      "Test size: 28367\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "\n",
    "# standardize\n",
    "inputs_val = (inputs_val - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "inputs_test = (inputs_test - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "inputs_train = (inputs_train - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_initial (LSTM)          (None, None, 16)          1792      \n",
      "_________________________________________________________________\n",
      "lstm_second (LSTM)           (None, None, 32)          6272      \n",
      "_________________________________________________________________\n",
      "lstm_third (LSTM)            (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_initial (Dense)        (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 41,345\n",
      "Trainable params: 41,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(16, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 11), return_sequences=True),\n",
    "        keras.layers.LSTM(32, activation=\"relu\", name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.LSTM(64, activation=\"relu\", name=\"lstm_third\"),\n",
    "        keras.layers.Dense(128, name=\"dense_initial\", activation=\"relu\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4137/4137 [==============================] - 66s 16ms/step - loss: 10.5881 - mae: 2.5837 - val_loss: 7.4037 - val_mae: 2.0058\n",
      "Epoch 2/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 7.8590 - mae: 2.1005 - val_loss: 6.6180 - val_mae: 1.8727\n",
      "Epoch 3/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 7.0258 - mae: 1.9602 - val_loss: 6.0529 - val_mae: 1.7851\n",
      "Epoch 4/500\n",
      "4137/4137 [==============================] - 66s 16ms/step - loss: 6.4042 - mae: 1.8620 - val_loss: 5.5982 - val_mae: 1.7069\n",
      "Epoch 5/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 5.8753 - mae: 1.7781 - val_loss: 5.1124 - val_mae: 1.6251\n",
      "Epoch 6/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 5.3006 - mae: 1.6816 - val_loss: 4.5376 - val_mae: 1.5291\n",
      "Epoch 7/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 4.7126 - mae: 1.5799 - val_loss: 3.9978 - val_mae: 1.4227\n",
      "Epoch 8/500\n",
      "4137/4137 [==============================] - 66s 16ms/step - loss: 4.2501 - mae: 1.4921 - val_loss: 3.6432 - val_mae: 1.3529\n",
      "Epoch 9/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 3.8762 - mae: 1.4171 - val_loss: 3.4257 - val_mae: 1.3149\n",
      "Epoch 10/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 3.6012 - mae: 1.3598 - val_loss: 3.1601 - val_mae: 1.2474\n",
      "Epoch 11/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 3.3985 - mae: 1.3153 - val_loss: 2.9479 - val_mae: 1.2011\n",
      "Epoch 12/500\n",
      "4137/4137 [==============================] - 73s 18ms/step - loss: 3.2445 - mae: 1.2810 - val_loss: 2.8512 - val_mae: 1.1785\n",
      "Epoch 13/500\n",
      "4137/4137 [==============================] - 70s 17ms/step - loss: 3.1344 - mae: 1.2561 - val_loss: 2.7308 - val_mae: 1.1457\n",
      "Epoch 14/500\n",
      "4137/4137 [==============================] - 68s 16ms/step - loss: 3.0512 - mae: 1.2362 - val_loss: 2.6545 - val_mae: 1.1283\n",
      "Epoch 15/500\n",
      "4137/4137 [==============================] - 68s 16ms/step - loss: 2.9924 - mae: 1.2218 - val_loss: 2.5902 - val_mae: 1.1157\n",
      "Epoch 16/500\n",
      "4137/4137 [==============================] - 69s 17ms/step - loss: 2.9545 - mae: 1.2116 - val_loss: 2.5617 - val_mae: 1.1093\n",
      "Epoch 17/500\n",
      "4137/4137 [==============================] - 68s 16ms/step - loss: 2.9178 - mae: 1.2042 - val_loss: 2.5326 - val_mae: 1.1005\n",
      "Epoch 18/500\n",
      "4137/4137 [==============================] - 63s 15ms/step - loss: 2.8907 - mae: 1.1979 - val_loss: 2.4929 - val_mae: 1.0936\n",
      "Epoch 19/500\n",
      "4137/4137 [==============================] - 69s 17ms/step - loss: 2.8648 - mae: 1.1911 - val_loss: 2.5162 - val_mae: 1.0988\n",
      "Epoch 20/500\n",
      "4137/4137 [==============================] - 67s 16ms/step - loss: 2.8449 - mae: 1.1870 - val_loss: 2.4538 - val_mae: 1.0772\n",
      "Epoch 21/500\n",
      "4137/4137 [==============================] - 63s 15ms/step - loss: 2.8283 - mae: 1.1831 - val_loss: 2.4356 - val_mae: 1.0786\n",
      "Epoch 22/500\n",
      "4137/4137 [==============================] - 62s 15ms/step - loss: 2.8114 - mae: 1.1792 - val_loss: 2.4164 - val_mae: 1.0720\n",
      "Epoch 23/500\n",
      "4137/4137 [==============================] - 68s 17ms/step - loss: 2.7979 - mae: 1.1765 - val_loss: 2.4123 - val_mae: 1.0741\n",
      "Epoch 24/500\n",
      "4137/4137 [==============================] - 71s 17ms/step - loss: 2.7866 - mae: 1.1739 - val_loss: 2.4086 - val_mae: 1.0614\n",
      "Epoch 25/500\n",
      "4137/4137 [==============================] - 69s 17ms/step - loss: 2.7788 - mae: 1.1712 - val_loss: 2.3915 - val_mae: 1.0621\n",
      "Epoch 26/500\n",
      "4137/4137 [==============================] - 69s 17ms/step - loss: 2.7693 - mae: 1.1696 - val_loss: 2.3869 - val_mae: 1.0641\n",
      "Epoch 27/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 2.7595 - mae: 1.1673 - val_loss: 2.3753 - val_mae: 1.0636\n",
      "Epoch 28/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 2.7515 - mae: 1.1656 - val_loss: 2.4114 - val_mae: 1.0724\n",
      "Epoch 29/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 2.7435 - mae: 1.1639 - val_loss: 2.4053 - val_mae: 1.0698\n",
      "Epoch 30/500\n",
      "4137/4137 [==============================] - 62s 15ms/step - loss: 2.7376 - mae: 1.1635 - val_loss: 2.3938 - val_mae: 1.0652\n",
      "Epoch 31/500\n",
      "4137/4137 [==============================] - 63s 15ms/step - loss: 2.7304 - mae: 1.1615 - val_loss: 2.3608 - val_mae: 1.0527\n",
      "Epoch 32/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 2.7255 - mae: 1.1603 - val_loss: 2.3631 - val_mae: 1.0515\n",
      "Epoch 33/500\n",
      "4137/4137 [==============================] - 62s 15ms/step - loss: 2.7202 - mae: 1.1590 - val_loss: 2.3544 - val_mae: 1.0578\n",
      "Epoch 34/500\n",
      "4137/4137 [==============================] - 62s 15ms/step - loss: 2.7161 - mae: 1.1584 - val_loss: 2.3608 - val_mae: 1.0587\n",
      "Epoch 35/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 2.7128 - mae: 1.1583 - val_loss: 2.3568 - val_mae: 1.0547\n",
      "Epoch 36/500\n",
      "4137/4137 [==============================] - 64s 15ms/step - loss: 2.7070 - mae: 1.1566 - val_loss: 2.3511 - val_mae: 1.0551\n",
      "Epoch 37/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 2.7032 - mae: 1.1552 - val_loss: 2.3303 - val_mae: 1.0446\n",
      "Epoch 38/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 2.6991 - mae: 1.1554 - val_loss: 2.3430 - val_mae: 1.0469\n",
      "Epoch 39/500\n",
      "4137/4137 [==============================] - 64s 16ms/step - loss: 2.6950 - mae: 1.1540 - val_loss: 2.3490 - val_mae: 1.0555\n",
      "Epoch 40/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 2.6910 - mae: 1.1540 - val_loss: 2.3679 - val_mae: 1.0590\n",
      "Epoch 41/500\n",
      "4137/4137 [==============================] - 66s 16ms/step - loss: 2.6882 - mae: 1.1524 - val_loss: 2.3449 - val_mae: 1.0477\n",
      "Epoch 42/500\n",
      "4137/4137 [==============================] - 64s 15ms/step - loss: 2.6855 - mae: 1.1522 - val_loss: 2.3524 - val_mae: 1.0495\n",
      "Epoch 43/500\n",
      "4137/4137 [==============================] - 63s 15ms/step - loss: 2.6804 - mae: 1.1515 - val_loss: 2.3322 - val_mae: 1.0449\n",
      "Epoch 44/500\n",
      "4137/4137 [==============================] - 62s 15ms/step - loss: 2.6793 - mae: 1.1513 - val_loss: 2.3431 - val_mae: 1.0500\n",
      "Epoch 45/500\n",
      "4137/4137 [==============================] - 62s 15ms/step - loss: 2.6750 - mae: 1.1504 - val_loss: 2.3433 - val_mae: 1.0434\n",
      "Epoch 46/500\n",
      "4137/4137 [==============================] - 65s 16ms/step - loss: 2.6723 - mae: 1.1495 - val_loss: 2.3582 - val_mae: 1.0507\n",
      "Epoch 47/500\n",
      "4137/4137 [==============================] - 69s 17ms/step - loss: 2.6685 - mae: 1.1486 - val_loss: 2.3623 - val_mae: 1.0512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64390bef0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/baseline_model_multivar.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887/887 [==============================] - 3s 4ms/step - loss: 2.9670 - mae: 1.2265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9669766426086426, 1.2264602184295654]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
