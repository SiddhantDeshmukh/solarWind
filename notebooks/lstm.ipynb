{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import heliopy.data.omni as omni\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "from optuna import visualization as viz\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = datetime(1995, 1, 1)\n",
    "END_TIME = datetime(2018, 2, 28)\n",
    "INPUT_LENGTH = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Load Data\n",
    "2. Split data into time series sections\n",
    "3. Split into train/val/test\n",
    "4. Baseline models\n",
    "5. Initial LSTM\n",
    "6. Multivar LSTM (repeating 2-5)\n",
    "7. Optuna multivar LSTM \n",
    "8. CNN preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omni_rtn_data(start_time, end_time):\n",
    "    identifier = 'OMNI_COHO1HR_MERGED_MAG_PLASMA'  # COHO 1HR data\n",
    "    omni_data = omni._omni(start_time, end_time, identifier=identifier, intervals='yearly', warn_missing_units=False)\n",
    "    return omni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_omni_rtn_data(START_TIME, END_TIME).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_field_strength = np.array(data[\"BR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split into INPUT_LENGTH sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (201389, 24, 1)\n",
      "Output shape: (201389,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([mag_field_strength[i:i + INPUT_LENGTH] \n",
    "                        for i in range(len(mag_field_strength) - INPUT_LENGTH)])[:, :, np.newaxis]\n",
    "outputs = np.array(mag_field_strength[INPUT_LENGTH:])\n",
    "\n",
    "nan_check = np.array([mag_field_strength[i:i + INPUT_LENGTH + 1] \n",
    "                      for i in range(len(mag_field_strength) - INPUT_LENGTH)])\n",
    "\n",
    "inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140972\n",
      "Val size: 30208\n",
      "Test size: 30209\n"
     ]
    }
   ],
   "source": [
    "# Doing this time-based, so most recent = test set, earliest = train set \n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "data_size = len(inputs)\n",
    "\n",
    "inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "print(\"Train size:\", len(inputs_train))\n",
    "print(\"Val size:\", len(inputs_val))\n",
    "print(\"Test size:\", len(inputs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1: Last timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE last_train: 3.14658\n",
      "MSE last_val: 2.4640298\n",
      "MSE last_test: 3.3855927\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"last_train\", \"last_val\", \"last_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, -1, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2: Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE mean_train: 6.9930334\n",
      "MSE mean_val: 5.7877436\n",
      "MSE mean_test: 6.955669\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"mean_train\", \"mean_val\", \"mean_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.mean(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3: Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE median_train: 7.735584\n",
      "MSE median_val: 6.426136\n",
      "MSE median_test: 7.6656737\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"median_train\", \"median_val\", \"median_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = np.median(dset, axis=(1, 2))\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4: Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE start_train: 15.318962\n",
      "MSE start_val: 12.723228\n",
      "MSE start_test: 15.642863\n"
     ]
    }
   ],
   "source": [
    "for name, dset, out in zip([\"start_train\", \"start_val\", \"start_test\"], \n",
    "                           [inputs_train, inputs_val, inputs_test],\n",
    "                           [outputs_train, outputs_val, outputs_test]):\n",
    "    baselines[name] = dset[:, 0, 0]\n",
    "    print(\"MSE {}:\".format(name), np.mean((baselines[name] - out) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initial LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 1), return_sequences=True),\n",
    "        keras.layers.LSTM(20, activation=\"relu\", name=\"lstm_second\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/baseline_model.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../models/baseline_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 - 3s - loss: 3.0155 - mean_absolute_error: 1.2339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0155394077301025, 1.2338838577270508]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_test, outputs_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Repeat above but use more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise all variables \n",
    "data_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (189110, 24, 11)\n",
      "Output shape: (189110,)\n",
      "Any Nans?: False\n"
     ]
    }
   ],
   "source": [
    "# Split into INPUT_LENGTH sections\n",
    "def split_data_into_sections(input_length=INPUT_LENGTH):\n",
    "    inputs = np.array([data_array[i:i + input_length] for i in range(len(data_array) - input_length)])\n",
    "    outputs = np.array(mag_field_strength[input_length:]) # np.array(data_array[INPUT_LENGTH:, 2])\n",
    "\n",
    "    nan_check = np.array([data_array[i:i + input_length + 1] for i in range(len(data_array) - input_length)])\n",
    "\n",
    "    inputs = inputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "    outputs = outputs[np.where([~np.any(np.isnan(i)) for i in nan_check])]\n",
    "\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Output shape:\", outputs.shape)\n",
    "\n",
    "    print(\"Any Nans?:\", np.any(np.isnan(outputs)) or np.any(np.isnan(inputs)))\n",
    "    return inputs, outputs\n",
    "inputs, outputs = split_data_into_sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 132377\n",
      "Val size: 28366\n",
      "Test size: 28367\n"
     ]
    }
   ],
   "source": [
    "def train_val_test_split(train_size=0.7, val_size=0.15):\n",
    "    train_size = 0.7\n",
    "    val_size = 0.15\n",
    "    data_size = len(inputs)\n",
    "\n",
    "    inputs_train, outputs_train = inputs[:int(train_size * data_size)], outputs[:int(train_size * data_size)]\n",
    "    inputs_val, outputs_val = inputs[int(train_size * data_size):int((train_size + val_size) * data_size)], outputs[int(train_size * data_size):int((train_size + val_size) * data_size)]\n",
    "    inputs_test, outputs_test = inputs[int((train_size + val_size) * data_size):], outputs[int((train_size + val_size) * data_size):]\n",
    "\n",
    "\n",
    "    # standardize\n",
    "    inputs_val = (inputs_val - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "    inputs_test = (inputs_test - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "    inputs_train = (inputs_train - np.nanmean(inputs_train, axis=(0, 1))) / np.nanstd(inputs_train, axis=(0, 1))\n",
    "\n",
    "\n",
    "    print(\"Train size:\", len(inputs_train))\n",
    "    print(\"Val size:\", len(inputs_val))\n",
    "    print(\"Test size:\", len(inputs_test))\n",
    "    return inputs_train, inputs_val, inputs_test, outputs_train, outputs_val, outputs_test\n",
    "inputs_train, inputs_val, inputs_test, outputs_train, outputs_val, outputs_test = train_val_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(16, activation=\"relu\", name=\"lstm_initial\", input_shape=(None, 11), return_sequences=True),\n",
    "        keras.layers.LSTM(32, activation=\"relu\", name=\"lstm_second\", return_sequences=True),\n",
    "        keras.layers.LSTM(64, activation=\"relu\", name=\"lstm_third\"),\n",
    "        keras.layers.Dense(128, name=\"dense_initial\", activation=\"relu\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/baseline_model_multivar.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_layers: int, num_in_lstm_layers: List[int], \n",
    "                 dense_layers: int, num_in_dense_layers: List[int]) -> keras.models.Model:\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(lstm_layers):\n",
    "        if i == 0:\n",
    "            if i + 1 != lstm_layers:\n",
    "                model.add(keras.layers.LSTM(num_in_lstm_layers[i], input_shape=(None, 11), return_sequences=True))\n",
    "            else:\n",
    "                model.add(keras.layers.LSTM(num_in_lstm_layers[i], input_shape=(None, 11)))\n",
    "        elif i != 0 and i + 1 == lstm_layers:\n",
    "            model.add(keras.layers.LSTM(num_in_lstm_layers[i]))\n",
    "        else:\n",
    "            model.add(keras.layers.LSTM(num_in_lstm_layers[i], input_shape=(None, 11), return_sequences=True))\n",
    "            \n",
    "    for i in range(dense_layers):\n",
    "        if i + 1 == dense_layers:\n",
    "            model.add(keras.layers.Dense(num_in_dense_layers[i], activation=\"linear\"))\n",
    "        else:\n",
    "            model.add(keras.layers.Dense(num_in_dense_layers[i], activation=\"relu\"))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 3)  # Reducing to 3 to save time for now \n",
    "    layer_choices = [[4, 8, 16, 32, 64, 128, 256], [8, 16, 32, 64, 128, 256, 512],\n",
    "                     [16, 32, 64, 128, 256, 512, 1024]]\n",
    "    lstm_layer_choice = trial.suggest_categorical(\"lstm_layer_choice\", layer_choices)\n",
    "    lstm_layer_choice = lstm_layer_choice[:lstm_layers]\n",
    "    \n",
    "    dense_layers = trial.suggest_int(\"dense_layers\", 1, 2)  # Reducing to 2 to save time for now \n",
    "    layer_choices = [[1024, 512, 256, 1], [512, 256, 128, 1], [128, 64, 32, 1]]\n",
    "    dense_layer_choice = trial.suggest_categorical(\"dense_layer_choice\", layer_choices)\n",
    "    dense_layer_choice = dense_layer_choice[4 - dense_layers:]\n",
    "    \n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 2e-1, 1e-2])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    \n",
    "    model = create_model(lstm_layers, lstm_layer_choice, dense_layers, dense_layer_choice)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "              batch_size=batch_size, epochs=500, \n",
    "              callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),\n",
    "                         keras.callbacks.ModelCheckpoint(\"../models/optuna_{}.h5\".format(trial.number), save_best_only=True)],\n",
    "              verbose=2)\n",
    "\n",
    "    return model.evaluate(inputs_val, outputs_val)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective, n_trials=100)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. CNN Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (189110, 24, 11)\n",
      "Output shape: (189110,)\n",
      "Any Nans?: False\n",
      "Train size: 132377\n",
      "Val size: 28366\n",
      "Test size: 28367\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = split_data_into_sections(input_length=24)\n",
    "inputs_train, inputs_val, inputs_test, outputs_train, outputs_val, outputs_test = train_val_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 11, 8)             360       \n",
      "_________________________________________________________________\n",
      "lstm_initial (LSTM)          (None, 11, 16)            1600      \n",
      "_________________________________________________________________\n",
      "dense_initial (Dense)        (None, 11, 32)            544       \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 11, 1)             33        \n",
      "=================================================================\n",
      "Total params: 2,537\n",
      "Trainable params: 2,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Conv1D(8, kernel_size=4, strides=2, activation=\"relu\", input_shape=(24, 11)),\n",
    "        keras.layers.LSTM(16, activation=\"relu\", name=\"lstm_initial\", return_sequences=True),\n",
    "        keras.layers.Dense(32, name=\"dense_initial\", activation=\"relu\"),\n",
    "        keras.layers.Dense(1, name=\"dense_final\", activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "model.fit(inputs_train, outputs_train, validation_data=(inputs_val, outputs_val),\n",
    "          batch_size=32, epochs=500, verbose=2,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=30),\n",
    "                     keras.callbacks.ModelCheckpoint(\"../models/cnn_model_multivar.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. WaveNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
